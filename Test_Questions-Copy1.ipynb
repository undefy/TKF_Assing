{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can you predict which NBA players will make the \"All-Star\" team?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part one: Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "import numba\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 'player_data.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data = pd.read_csv(\"player_data.csv\")\n",
    "player_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data = player_data.drop([player_data.columns[0]] ,  axis='columns')\n",
    "cl_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove null values from \"Players\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data = cl_data.dropna(subset=['Player'])\n",
    "cl_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace null values with 0's in the '3P%' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data['3P%'] = cl_data['3P%'].fillna(0)\n",
    "cl_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows for players who started their careers before the 1980 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data = cl_data.drop(cl_data[cl_data.Year < 1980].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the 'all_star_appearances.pickle' file and use this data to create a column called 'all_star' that indicates whether or not a player made the All-Star team for a given year\n",
    "- This file is a dictionary in which the keys are players who've made an All-Star team in their careers\n",
    "- The values are all the years that the corresponding player made an All-Star team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure this column is binary where 1 = Made All-Star team, and 0 = Did not make All-Star team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asa_dict = pickle.load( open( \"all_star_appearances.pickle\", \"rb\" ) )\n",
    "asa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/42232728/pandas-creating-a-dataframe-from-a-dictionary\n",
    "# Convert each list to a Series and make the dataframe\n",
    "asa_df = pd.DataFrame(dict([ (k,Series(list(v))) for k,v in asa_dict.items() ]))\n",
    "asa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/60333701/pandas-remove-index-after-stacking\n",
    "asa_new = asa_df.stack().reset_index(level=0, drop=True).reset_index(name='year')\n",
    "asa_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asa_new[\"all_star\"]= 1\n",
    "asa_new.columns = [\"Player\",\"Year\",\"all_star\"]\n",
    "asa_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JL_DATA = cl_data.merge(asa_new, on=[\"Player\",\"Year\"], how=\"left\")\n",
    "JL_DATA[\"all_star\"] = JL_DATA[\"all_star\"].fillna(0)\n",
    "JL_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame.from_dict(asa_dict, orient=\"index\")\n",
    "#df = pd.DataFrame(asa_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_pickle(\"all_star_appearances.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate descriptive stats for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JL_DATA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JL_DATA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if the data set is not too big i use this all in onetool in order to get abetter understanding of the data\n",
    "JL_DATA.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save the profiling report in an easy to read html format\n",
    "profile = JL_DATA.profile_report(title='Pandas Profiling Report')\n",
    "profile.to_file(\"NBA data profiling.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a corr map of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = JL_DATA.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(20,20))\n",
    "corr = JL_DATA.corr()\n",
    "sns.heatmap(corr, annot=True, cmap=sns.diverging_palette(20, 220, n=200))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph the distibution of the 'Age' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below graph makes sense the yunger you re the more athletic you are. How ever from the above we can see that age is not very strongly correlated with other features.\n",
    "sns.distplot(JL_DATA.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classifier that predicts whether or not a player makes an All-Star team based on their stats for that season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droped pos and team as they do not affect personal score card much\n",
    "X = JL_DATA.drop([\"all_star\",\"Player\",\"Pos\",\"Tm\"], axis=1)\n",
    "y = JL_DATA[\"all_star\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the data was small was able to quickly use AutoML\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "#tpot.export('tpot_all-star_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there is imbalance its better to use the F1 metric\n",
    "tpot2 = TPOTClassifier(generations=5, population_size=50, verbosity=2, scoring = \"f1_macro\", random_state=42)\n",
    "tpot2.fit(X_train, y_train)\n",
    "print(tpot2.score(X_test, y_test))\n",
    "#tpot.export('tpot_all-star_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = JL_DATA.drop([\"all_star\",\"Player\"], axis=1)\n",
    "y = JL_DATA[\"all_star\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_features_index = np.where(X.dtypes != float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(eval_metric='F1',use_best_model=True,verbose = 200,random_seed=42)\n",
    "model.fit(X_train, y_train, cat_features=categ_features_index,eval_set=(X_test, y_test),use_best_model=True,plot=True)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick alternative testing\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    iterations=5, \n",
    "    learning_rate=0.1, \n",
    "    #loss_function='CrossEntropy'\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train, \n",
    "        \n",
    "        eval_set=(X_test, y_test), \n",
    "        verbose=False\n",
    ")\n",
    "\n",
    "print('CatBoost model is fitted: ' + str(clf.is_fitted()))\n",
    "print('CatBoost model parameters:')\n",
    "print(clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
